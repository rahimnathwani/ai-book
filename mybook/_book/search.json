[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI Agents for the IT Professional",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "1  The AI You Already Know",
    "section": "",
    "text": "1.1 Classification Models: The Workhorse of Traditional AI\nEstablishing context for readers who have used AI but haven’t built with it\nYou’ve likely used AI dozens of times already this week. When your email filtered out spam, when your phone unlocked by recognizing your face, when a store’s website recommended products you might like—these are all AI systems at work. They’re so integrated into our daily experience that we rarely pause to think about what’s happening under the hood.\nBut if you’re reading this book, you’re probably interested in moving beyond being a user of AI systems to being a builder of them. And to build effectively with the latest generation of AI agents, it’s helpful to first understand what AI looked like before agents came along.\nThis chapter establishes that foundation. We’ll explore the AI models you’ve been using, likely without realizing it, and understand both what they are and—critically—what they are not. This contrast will prepare you for the fundamental shift that generative models and agents represent.\nFor most of AI’s history in production systems, the dominant pattern has been classification. At its core, classification is about mapping inputs to predefined categories. You give the model some data, and it tells you which bucket that data belongs to.",
    "crumbs": [
      "Part I: Foundations — Understanding the AI Landscape",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The AI You Already Know</span>"
    ]
  },
  {
    "objectID": "chapter1.html#classification-models-the-workhorse-of-traditional-ai",
    "href": "chapter1.html#classification-models-the-workhorse-of-traditional-ai",
    "title": "1  The AI You Already Know",
    "section": "",
    "text": "1.1.1 Image Classification\nConsider a bird identification app. You take a photo of a bird, and the app tells you it’s a “Northern Cardinal” with 94% confidence. Under the hood, this is typically powered by a Convolutional Neural Network (CNN), a type of model specifically designed to process images.\nThe CNN was trained on thousands of labeled images—pictures of cardinals tagged “Northern Cardinal,” pictures of blue jays tagged “Blue Jay,” and so on. Through training, it learned to recognize the patterns of colors, shapes, and textures that distinguish one bird species from another. When you submit your photo, the model processes it through many layers of learned transformations and outputs a probability distribution across all the bird species it knows about.\nWhat this model is: A highly specialized pattern recognition system that maps images to predefined categories.\nWhat this model is not: A system that understands what a bird is, can describe why it made its choice, or can generate new images of birds.\n\n\n1.1.2 Sequence Classification\nText classification follows a similar pattern. Sentiment analysis—determining whether a product review is positive, negative, or neutral—is a classic example. Historically, models like Recurrent Neural Networks (RNNs) or Long Short-Term Memory (LSTM) networks were used for these tasks.\nAn LSTM processes text sequentially, word by word, maintaining an internal state that helps it understand context. After processing “The food was delicious but the service was terrible,” it might output: 60% probability of “Mixed” sentiment, 25% “Negative,” 15% “Positive.”\nAgain, the model maps input (text) to predefined categories (sentiment labels). It doesn’t compose new reviews, doesn’t understand the concept of customer service, and can’t engage in a conversation about the restaurant.\n\n\n1.1.3 The Classification Pattern\nThe fundamental architecture of classification-based AI systems is straightforward:\n\nTraining phase: The model learns from labeled examples (supervised learning)\nInference phase: New inputs are mapped to the learned categories\nOutput: A category label, often with a confidence score\n\nThis pattern has powered countless successful applications:\n\nSpam detection (spam vs. not spam)\nMedical image analysis (tumor vs. no tumor)\nVoice assistants understanding commands (play music, set alarm, check weather)\nCredit card fraud detection (legitimate vs. fraudulent)\nHandwriting recognition (mapping handwritten digits to 0-9)\n\nThe beauty of classification is its predictability and specificity. The model does exactly what it was trained to do: recognize patterns it has seen before and categorize new examples accordingly.\nThe limitation is equally clear: the model cannot handle anything outside its predefined categories. Show a bird classifier a picture of a dog, and it will still tell you it’s some species of bird (whichever one the dog looks most like). It has no concept of “I don’t know” or “this isn’t a bird”—unless you explicitly train it on a “not a bird” category.",
    "crumbs": [
      "Part I: Foundations — Understanding the AI Landscape",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The AI You Already Know</span>"
    ]
  },
  {
    "objectID": "chapter1.html#beyond-classification-other-recognition-models",
    "href": "chapter1.html#beyond-classification-other-recognition-models",
    "title": "1  The AI You Already Know",
    "section": "1.2 Beyond Classification: Other Recognition Models",
    "text": "1.2 Beyond Classification: Other Recognition Models\nWhile classification is the foundation, modern AI systems often need to do more than just assign a single label to an entire input. They need to find objects, locate text, or identify precise regions of interest. These recognition tasks build on classification but add spatial or structural awareness.\n\n1.2.1 Object Detection\nConsider a self-driving car’s vision system. It doesn’t just need to know “there is a pedestrian in this image.” It needs to know where the pedestrian is, along with where the cars are, where the traffic lights are, and where the lane markings are—all simultaneously.\nObject detection models like YOLO (You Only Look Once) or Faster R-CNN extend classification by:\n\nProposing multiple regions of interest within an image\nClassifying what’s in each region\nDrawing bounding boxes around detected objects\nOutputting multiple classifications per image, each with location data\n\nThe output might be: “Person at coordinates (120, 45, 200, 300), 96% confidence; Car at coordinates (450, 100, 680, 250), 89% confidence; Stop sign at coordinates (50, 30, 100, 80), 94% confidence.”\nThis is still fundamentally classification—just repeated across many regions of the image. The model identifies and locates things, but it doesn’t understand the scene, can’t predict what will happen next, and can’t generate an image of a car.\n\n\n1.2.2 Image Segmentation\nGoing a step further, segmentation models classify every single pixel in an image. Instead of drawing boxes around objects, they create precise masks.\nIn medical imaging, for instance, a segmentation model might highlight every pixel belonging to a tumor in an MRI scan. This pixel-level classification enables precise measurement and analysis.\nIn consumer applications, the “portrait mode” blur effect on smartphone cameras uses segmentation to identify exactly which pixels are the person (keep in focus) versus the background (blur).\n\n\n1.2.3 Optical Character Recognition (OCR)\nOCR is another specialized recognition task. Point your phone at a document, and apps can extract the text. Systems like Tesseract or modern deep learning OCR models:\n\nDetect regions of text in an image\nSegment individual characters or words\nClassify each character\nOutput the recognized text\n\nModern OCR systems can handle complex layouts, multiple languages, and varying fonts with impressive accuracy. But fundamentally, they’re still recognizing patterns they were trained on and mapping them to predefined characters.\n\n\n1.2.4 What These Models Are and Aren’t\nAll these recognition models share key characteristics:\nWhat they are: - Pattern recognition systems trained on specific types of data - Highly specialized for particular tasks (images → labels, images → boxes, images → text) - Deterministic in architecture (though individual predictions may vary slightly) - Fast and efficient at inference time - Excellent at tasks they were specifically trained for\nWhat they are not: - General-purpose reasoning systems - Capable of understanding context or meaning deeply - Able to handle tasks outside their training domain - Creative or generative - Able to explain their decisions in natural language\nThese models identify and locate things in data. They’re the AI equivalent of a highly skilled specialist who can instantly recognize thousands of specific patterns but can’t step outside their narrow expertise.",
    "crumbs": [
      "Part I: Foundations — Understanding the AI Landscape",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The AI You Already Know</span>"
    ]
  },
  {
    "objectID": "chapter1.html#how-ai-has-traditionally-been-integrated-into-software",
    "href": "chapter1.html#how-ai-has-traditionally-been-integrated-into-software",
    "title": "1  The AI You Already Know",
    "section": "1.3 How AI Has Traditionally Been Integrated into Software",
    "text": "1.3 How AI Has Traditionally Been Integrated into Software\nUnderstanding how classification and recognition models have been integrated into traditional software is crucial for appreciating how different AI agents are.\n\n1.3.1 The API Call Pattern\nHistorically, AI has been treated as a black box service within larger software systems. The pattern looks like this:\nSoftware: \"Here's some data. What category is it?\"\nAI Model: \"Category B, 87% confidence.\"\nSoftware: \"Thank you. I'll proceed accordingly.\"\nThe AI component is essentially a sophisticated function call. You send data in, you get a label (and maybe a confidence score) back. The software remains firmly in control of the decision-making.\n\n\n1.3.2 Examples in Practice\nEmail spam filtering:\nEmail arrives → Extract features (sender, content, links, etc.)\n             → Send to spam classifier\n             → Receive: \"spam\" (95% confidence)\n             → Move to spam folder\nThe email client makes all the decisions. The AI model just provides one piece of information (spam probability) that the client uses in its predetermined workflow.\nDocument processing:\nUpload receipt image → Send to OCR service\n                     → Receive: Extracted text\n                     → Parse text with regular expressions\n                     → Extract total amount\n                     → Store in database\nThe OCR is just one step in a traditional, deterministic pipeline. The application logic controls the entire flow.\nContent moderation:\nUser submits comment → Send to toxicity classifier\n                     → Receive: \"toxic\" (72% confidence)\n                     → If confidence &gt; 80%: Auto-reject\n                     → Else if confidence &gt; 50%: Queue for human review\n                     → Else: Auto-approve\nNotice how the software defines exact thresholds and workflows. The AI provides a score; the software decides what to do with it.\n\n\n1.3.3 The Software Stays “Normal”\nThis integration pattern has a crucial property: the software remains deterministic, predictable, and in control.\nThe AI component might use neural networks and complex mathematics internally, but from the software’s perspective, it’s just a function that returns a value. You can write traditional unit tests, set up monitoring, handle errors in familiar ways, and reason about the system’s behavior using standard software engineering practices.\nThe AI is a tool the software uses, not a partner that makes decisions.\n\n\n1.3.4 The Limitations of This Pattern\nThis approach has served us well for many applications, but it has fundamental limitations:\n\nFixed categories: You can only get answers to questions you anticipated during training\nNo reasoning: The model can’t think through multi-step problems or adapt its approach\nNo generation: These models recognize and classify; they don’t create\nNo context accumulation: Each API call is independent; the model doesn’t remember previous interactions\nSoftware brittleness: Every possible scenario must be anticipated and coded\n\nIf you want the system to do something new, you need to either: - Retrain or fine-tune the model with new categories - Write new code to handle the new workflow - Or both\nThe system cannot adapt on its own. It cannot handle novel situations it wasn’t explicitly programmed for.",
    "crumbs": [
      "Part I: Foundations — Understanding the AI Landscape",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The AI You Already Know</span>"
    ]
  },
  {
    "objectID": "chapter1.html#the-foundation-weve-built",
    "href": "chapter1.html#the-foundation-weve-built",
    "title": "1  The AI You Already Know",
    "section": "1.4 The Foundation We’ve Built",
    "text": "1.4 The Foundation We’ve Built\nThe AI you already know—the classification models and recognition systems—represents the first generation of production AI. These systems are narrow, specialized, and require explicit programming for every behavior.\nThey’ve been immensely valuable: - They’ve automated tasks that were previously impossible to automate at scale - They’ve provided capabilities (like image recognition) that traditional algorithms couldn’t approach - They’ve been deployed successfully in countless applications - They’ve established patterns and best practices for AI integration\nBut they’ve also been fundamentally limited by their nature. They’re tools that software uses, not collaborators that reason and decide.\nThis is the baseline. This is what AI looked like before generative models and agents entered the picture. As we’ll see in the next chapter, the shift from classification to generation isn’t just an incremental improvement—it’s a fundamental change in what AI systems can do and how we work with them.\nBefore we move on, internalize this contrast:\nTraditional AI: Software asks, “What category is this?” AI answers. Software decides what to do next.\nThe coming shift: You’ll describe a goal. The AI will figure out how to achieve it, what tools to use, and what steps to take. The AI becomes the decision-maker.\nThat shift changes everything. And it starts with understanding what generative models actually are.",
    "crumbs": [
      "Part I: Foundations — Understanding the AI Landscape",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The AI You Already Know</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "chapter2.html",
    "href": "chapter2.html",
    "title": "2  The Generative Revolution",
    "section": "",
    "text": "2.1 What Generative Models Actually Do\nUnderstanding what makes modern AI different\nIn 2022, something changed. Suddenly, everyone was talking about AI again—not just in tech circles, but at dinner tables, in boardrooms, and on the news. DALL-E created images from text descriptions. ChatGPT wrote essays, debugged code, and held conversations that felt surprisingly human. Within months, generative AI went from a research curiosity to a cultural phenomenon.\nBut what actually changed? Why are these new AI systems fundamentally different from the classification and recognition models we explored in Chapter 1?\nThe answer lies in a deceptively simple shift: from recognition to generation. Instead of mapping inputs to predefined categories, these models create new content. And that capability unlocks possibilities that classification-based AI could never approach.\nAt the heart of generative AI is a profound insight: prediction and generation are the same thing.",
    "crumbs": [
      "Part I: Foundations — Understanding the AI Landscape",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Generative Revolution</span>"
    ]
  },
  {
    "objectID": "chapter2.html#what-generative-models-actually-do",
    "href": "chapter2.html#what-generative-models-actually-do",
    "title": "2  The Generative Revolution",
    "section": "",
    "text": "2.1.1 The Core Insight\nTraditional classification asks: “Which category does this belong to?”\nGenerative models ask: “What comes next?”\nThat subtle reframing changes everything.\n\n\n2.1.2 Diffusion Models: Creating Images from Noise\nConsider how modern image generation works. Models like Stable Diffusion or DALL-E 2 don’t have a database of images they’re retrieving. They’re not copy-pasting parts of training images together. Instead, they learned a very specific skill: removing noise.\nHere’s the process:\n\nDuring training, the model saw millions of images\nFor each image, random noise was progressively added until the image became pure static\nThe model learned to reverse this process—to predict what the image looked like before noise was added\nAfter training, you give it pure noise plus a text description\nThe model iteratively removes noise, guided by the description, until a coherent image emerges\n\nAt each step, the model is predicting: “Given this noisy image and this description, what should the slightly less noisy version look like?” Generation happens through repeated prediction.\nThe result is genuinely new images. The model hasn’t seen a photo of “an astronaut riding a horse on Mars” during training, but it learned the visual patterns of astronauts, horses, and Martian landscapes. It can combine these learned patterns in novel ways.\nWhat this is: A model that creates new content by learning and combining patterns from training data.\nWhat this is not: A database that retrieves or copies stored images. The model generates pixel by pixel through learned transformations.\n\n\n2.1.3 LLMs: Generating Text One Token at a Time\nLarge Language Models (LLMs) like GPT-4, Claude, or Gemini work on the same principle, applied to text.\nA token is roughly ¾ of a word (we’ll explore this more in the next section). When you ask ChatGPT a question, here’s what actually happens:\n\nYour question is converted into tokens\nThe model predicts the most likely next token\nThat token is added to the context\nThe model predicts the next token after that\nThis continues until the model predicts a “stop” token\n\nEach prediction is based on everything that came before. The model asks itself: “Given this entire conversation so far, what token should come next?”\nConsider this example:\nYour prompt: “Explain photosynthesis in simple terms.”\nThe model generates: - “Photosynthesis” (predicted as a good starting token) - ” is” (predicted to follow “Photosynthesis”) - ” the” (predicted to follow “Photosynthesis is”) - ” process” (predicted to follow “Photosynthesis is the”) - …and so on, one token at a time\nEach token is a prediction based on patterns learned from vast amounts of text during training. The model learned that after “Photosynthesis is the,” words like “process,” “way,” or “method” are highly probable. It learned that explanations about scientific concepts often follow certain structural patterns.\nThe model is generating original text, not retrieving stored answers. It doesn’t have a pre-written explanation of photosynthesis in a database. It’s composing the explanation token by token, using learned linguistic and conceptual patterns.\nWhat this is: A model that generates text by predicting probable next tokens based on learned patterns.\nWhat this is not: A database that stores and retrieves facts. The model doesn’t “look up” information—it generates responses based on statistical patterns in its training data.\n\n\n2.1.4 The Implications of Generation\nThis shift from recognition to generation has profound implications:\n\nCreativity within learned patterns: The model can produce content it has never seen, as long as it’s a plausible combination of patterns it has learned.\nFlexibility: Instead of being limited to predefined categories, the model can generate responses to arbitrary prompts.\nUnpredictability: Because generation involves probabilistic predictions, the same input can produce different outputs (though this can be controlled with temperature and other parameters).\nNo ground truth: Unlike classification, where you can check if “this is a cat” is correct, generated content exists on a spectrum from “good” to “bad” to “wrong,” often with subjective judgment involved.\nHallucination: Because the model generates based on patterns rather than retrieving facts, it can confidently generate plausible-sounding but entirely false information.\n\nThese characteristics make generative models powerful and versatile—but also fundamentally different to work with than classification models.",
    "crumbs": [
      "Part I: Foundations — Understanding the AI Landscape",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Generative Revolution</span>"
    ]
  },
  {
    "objectID": "chapter2.html#how-llms-are-trained",
    "href": "chapter2.html#how-llms-are-trained",
    "title": "2  The Generative Revolution",
    "section": "2.2 How LLMs Are Trained",
    "text": "2.2 How LLMs Are Trained\nUnderstanding how these models are trained helps you understand both their capabilities and their limitations. LLM training typically happens in multiple stages, each serving a different purpose.\n\n2.2.1 Pretraining: Learning Language\nThe first and most expensive stage is pretraining. This is where the model learns language itself.\nThe process: 1. Gather an enormous corpus of text (books, websites, articles, code, conversations) 2. For each sequence of tokens, train the model to predict the next token 3. Repeat billions of times across the entire corpus 4. Adjust the model’s parameters (billions of them) to get better at prediction\nThis is unsupervised learning—the model doesn’t need labeled data. The text itself provides the labels: given tokens 1 through N, predict token N+1.\nThrough this process, the model learns: - Grammar and syntax (“The cat sat on the” → “mat” is more likely than “elephant”) - Factual associations (“The capital of France is” → “Paris”) - Common reasoning patterns (cause-effect relationships, logical progressions) - Domain knowledge (medical terminology, programming concepts, historical events) - Cultural references and context\nWhat pretraining produces: A model that’s very good at predicting plausible text continuations but not necessarily good at following instructions or being helpful.\nA pretrained model might complete “How do I bake a cake?” with “is a question many people ask” rather than actually providing instructions. It’s predicting likely text continuations, not trying to be a helpful assistant.\n\n\n2.2.2 Fine-Tuning: Following Instructions\nThe next stage is fine-tuning (also called supervised fine-tuning or SFT). This is where the model learns to be an assistant.\nThe process: 1. Create a dataset of (instruction, desired response) pairs - Question: “Explain gravity” → Response: [Good explanation] - Request: “Write a poem about trees” → Response: [Actual poem] - Task: “Debug this code” → Response: [Helpful debugging steps] 2. Train the model on these examples 3. The model learns the pattern: “When given an instruction, generate a helpful response”\nAfter fine-tuning, “How do I bake a cake?” gets a recipe instead of meta-commentary about the question.\nFine-tuning typically uses far less data than pretraining (thousands to hundreds of thousands of examples vs. billions of text sequences). It’s not teaching the model new knowledge—it’s teaching the model how to format and present the knowledge it already has.\n\n\n2.2.3 RLHF: Learning from Human Feedback\nThe final stage is Reinforcement Learning from Human Feedback (RLHF). This is where the model learns human preferences about quality, tone, and safety.\nThe process: 1. Generate multiple responses to the same prompt 2. Human raters rank these responses (best to worst) 3. Train a “reward model” to predict human preferences 4. Use reinforcement learning to adjust the model to produce responses that score higher according to the reward model\nThis is how models learn: - To refuse harmful requests - To be concise when appropriate and detailed when needed - To admit uncertainty rather than confidently hallucinating - To be helpful without being sycophantic - To follow nuanced human preferences that are hard to specify explicitly\nRLHF is what makes the difference between a model that can generate text and an assistant that’s actually pleasant and safe to interact with.\n\n\n2.2.4 Why This Training Matters to You\nUnderstanding this training pipeline helps you understand:\n\nKnowledge cutoff: The model only knows training data up to a certain date. It can’t know about events that happened after training.\nPatterns, not facts: The model learned statistical associations. It might “know” that Paris is the capital of France because that pattern appeared thousands of times in training, but it doesn’t have a structured database of facts.\nConfidence without correctness: The model generates plausible text based on patterns. It can be very confident about completely wrong information if the wrong information follows plausible patterns.\nInstruction-following capability: The model can follow complex instructions because it was explicitly trained to do so, not because language models inherently understand commands.\nLimitations: If a capability wasn’t in the training data or wasn’t reinforced during fine-tuning and RLHF, the model probably won’t have it.",
    "crumbs": [
      "Part I: Foundations — Understanding the AI Landscape",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Generative Revolution</span>"
    ]
  },
  {
    "objectID": "chapter2.html#the-context-window-an-llms-working-memory",
    "href": "chapter2.html#the-context-window-an-llms-working-memory",
    "title": "2  The Generative Revolution",
    "section": "2.3 The Context Window: An LLM’s Working Memory",
    "text": "2.3 The Context Window: An LLM’s Working Memory\nOne of the most important concepts for understanding and working with LLMs is the context window—the model’s working memory for any given interaction.\n\n2.3.1 What Tokens Are\nFirst, let’s clarify tokens. LLMs don’t work directly with words or characters. They work with tokens, which are chunks of text that the model processes as units.\nAs a rough heuristic: 1 token ≈ ¾ of a word in English.\nExamples: - “cat” = 1 token - “butterfly” = 2 tokens (“butter” + “fly”) - “photosynthesis” = 4 tokens - “ChatGPT” = 2 tokens - “don’t” = 2 tokens (“don” + “’t”)\nProgramming code, special characters, and non-English languages can have different token densities.\nWhy tokens instead of words? Tokens allow the model to handle any text efficiently—including made-up words, code, mathematical symbols, and languages with different word structures.\n\n\n2.3.2 Context Window Size\nThe context window is measured in tokens. Modern LLMs have context windows ranging from:\n\nEarly GPT-3: 4,096 tokens (~3,000 words)\nGPT-4: 8,192 to 128,000 tokens (depending on version)\nClaude 2: 100,000 tokens (~75,000 words)\nClaude 3: 200,000 tokens\nGemini 1.5: 1,000,000+ tokens\n\nThese numbers are increasing rapidly. By the time you read this, they may be larger.\n\n\n2.3.3 What Fits in Context\nLet’s make this concrete. A 100,000 token context window can hold approximately:\n\nA full novel (~75,000 words)\n50-100 pages of technical documentation\nAn entire codebase of a small to medium application\nA complete conversation history with hundreds of back-and-forth messages\n\nThis is the model’s complete awareness for any single response. Everything in the context window is “visible” to the model when it generates its next token.\n\n\n2.3.4 What This Is and Isn’t\nWhat the context window is: - The model’s working memory for the current conversation - Everything the model can “see” when generating a response - Includes system prompts, conversation history, and any documents you’ve provided - Completely fresh for each new conversation\nWhat the context window is not: - Long-term memory that persists between conversations - A database where the model looks up information - Selective (the model can’t choose to ignore parts of the context) - Infinite (there are hard limits, though they’re growing)\n\n\n2.3.5 Implications for Working with LLMs\nThe context window has crucial implications:\n\nStateless conversations: Each API call is independent. If you want the model to remember something, you must include it in every request. (Chat interfaces handle this for you by automatically including conversation history.)\nContext management matters: Once you hit the limit, older messages must be removed or summarized. The model can’t remember what fell out of the window.\nEverything counts: System prompts, your messages, the model’s responses, and any documents you include all consume the same context window.\nRetrieval becomes necessary: For knowledge bases larger than the context window, you need strategies like RAG (Retrieval-Augmented Generation, covered in Chapter 10) to bring relevant information into context.\nCost implications: Larger contexts cost more. You pay for input and output tokens, so including a 50,000-token document in every request adds up quickly.\n\nThink of the context window like RAM in a computer. It’s fast and fully accessible, but limited. Everything the model can work with must fit in this space.",
    "crumbs": [
      "Part I: Foundations — Understanding the AI Landscape",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Generative Revolution</span>"
    ]
  },
  {
    "objectID": "chapter2.html#system-prompts-vs.-user-prompts",
    "href": "chapter2.html#system-prompts-vs.-user-prompts",
    "title": "2  The Generative Revolution",
    "section": "2.4 System Prompts vs. User Prompts",
    "text": "2.4 System Prompts vs. User Prompts\nWhen you interact with an LLM, there are actually two types of messages shaping its behavior: system prompts and user prompts. Understanding the distinction is essential for effective use of AI agents.\n\n2.4.1 System Prompt: The Job Description\nThe system prompt (also called system message or system instruction) is set by the application developer, not the end user. It’s the model’s “job description” and “training manual.”\nExample system prompt:\nYou are a helpful customer support agent for Acme Corp.\nYou have access to customer order history and can process\nreturns. Be polite and professional. If you cannot answer\na question, direct the customer to human support.\nAlways verify customer identity before accessing account information.\nThis prompt is typically: - Set once at the beginning of a conversation - Not visible to the end user (though many applications now show it for transparency) - The same for all users of the application - Used to define the model’s role, capabilities, constraints, and personality\nThe system prompt is where you configure the agent’s behavior at the application level.\n\n\n2.4.2 User Prompt: The Work Request\nThe user prompt is what the end user types—their actual question, command, or request.\nExample user prompts: - “Where is my order #12345?” - “I want to return the blue widget I ordered last week” - “What are your business hours?”\nUser prompts are: - Different for every interaction - The specific task or question the user wants addressed - Processed in the context of the system prompt\n\n\n2.4.3 How They Interact\nWhen you send a message to an LLM, the actual context looks like this:\n[System] You are a helpful customer support agent for Acme Corp...\n[User] Where is my order #12345?\n[Assistant] Let me look that up for you. [searches order history]\n[User] When will it arrive?\n[Assistant] According to the tracking information...\nThe system message persists throughout the conversation, shaping how the model interprets and responds to each user message.\n\n\n2.4.4 Practical Examples\nCode debugging assistant:\n[System] You are an expert Python debugger. When given code\nwith errors, explain what's wrong and suggest fixes. Include\nexplanations of why the error occurred.\n\n[User] This code crashes: [code snippet]\n\n[Assistant] The issue is on line 5... [detailed explanation]\nCreative writing partner:\n[System] You are a creative writing assistant. Help users\ndevelop story ideas, characters, and plots. Be encouraging\nand build on their ideas rather than replacing them.\n\n[User] I have an idea for a sci-fi story about Mars\n\n[Assistant] That's a great starting point! What aspect of\nMars interests you most—the colonization challenges, the\nisolation, the scientific discoveries?\nData analyst agent:\n[System] You are a data analyst. You have access to tools\nfor running SQL queries and creating visualizations. When\nanalyzing data, always verify assumptions and note limitations.\n\n[User] What were our top-selling products last quarter?\n\n[Assistant] I'll query the sales database... [uses SQL tool]\n\n\n2.4.5 What These Are and Are Not\nWhat system prompts are: - Configuration for the model’s behavior and role - Persistent context that shapes all responses - The application developer’s way to customize the model - Instructions that carry more weight than user messages (usually)\nWhat system prompts are not: - Absolute constraints that cannot be overridden (careful prompt engineering by users can sometimes work around them) - Programming in the traditional sense (they’re natural language suggestions, not code) - Guarantees of behavior (the model interprets them probabilistically)\nWhat user prompts are: - The specific work request or question - Variable content from each user - Interpreted in the context of the system prompt\nWhat user prompts are not: - The only input shaping the response (the system prompt is equally important) - Limited to questions (they can be commands, document analysis requests, code to debug, etc.)\n\n\n2.4.6 The Interaction Pattern\nThe power comes from the combination:\n\nSystem prompt defines what kind of assistant the model is\nUser prompt defines what the user wants done\nModel response is shaped by both\n\nThis separation allows developers to create specialized AI assistants without fine-tuning the model. Want a coding assistant? Write a system prompt that emphasizes code help. Want a creative writing partner? Write a different system prompt. Same underlying model, different configured behavior.",
    "crumbs": [
      "Part I: Foundations — Understanding the AI Landscape",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Generative Revolution</span>"
    ]
  },
  {
    "objectID": "chapter2.html#the-revolution-summarized",
    "href": "chapter2.html#the-revolution-summarized",
    "title": "2  The Generative Revolution",
    "section": "2.5 The Revolution Summarized",
    "text": "2.5 The Revolution Summarized\nThe shift from classification to generation represents a fundamental change in what AI systems can do:\nTraditional AI: - Recognizes patterns and assigns categories - Limited to predefined outputs - Deterministic within narrow domains - Software remains in control\nGenerative AI: - Creates new content through prediction - Generates arbitrary text or images - Probabilistic and creative - Flexible instruction following\nThe enablers: - Training at scale (pretraining on vast text corpora) - Instruction fine-tuning (learning to be helpful assistants) - RLHF (aligning with human preferences) - Growing context windows (expanding working memory) - System prompts (configurable behavior without retraining)\nBut here’s the key insight for this book: even generative models, used alone, are not agents.\nIf you simply call an LLM API with a prompt and receive a text response, you’re still in the traditional integration pattern. The software sends data (the prompt), receives data (the generated text), and decides what to do next.\nThe agent revolution—which we’ll explore in the coming chapters—happens when we give these generative models the ability to take actions, use tools, and make decisions about what to do next.\nFirst, though, we need to understand the middle ground: AI-powered workflows. These represent the bridge between traditional AI and true agents, and understanding them will clarify what makes agents special.\nThat’s where we’re headed in Chapter 3.",
    "crumbs": [
      "Part I: Foundations — Understanding the AI Landscape",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Generative Revolution</span>"
    ]
  },
  {
    "objectID": "chapter3.html",
    "href": "chapter3.html",
    "title": "3  AI-Powered Workflows",
    "section": "",
    "text": "3.1 What Workflows Are\nThe intermediate step most teams should start with\nYou’ve seen how traditional AI works through classification and recognition (Chapter 1), and you understand the revolutionary capabilities of generative models (Chapter 2). Now comes a critical question: How do you actually integrate these powerful new models into your existing systems?\nThe answer, for most practical business applications, is not to jump straight to autonomous agents. Instead, the sweet spot for most teams is AI-powered workflows—systems where traditional software orchestrates AI capabilities to accomplish specific tasks.\nThis chapter explores what workflows are, how they differ from both traditional systems and true agents, and why they represent the pragmatic starting point for most AI integration projects.\nAn AI-powered workflow is a traditional software system that uses AI models as components within a predetermined process. The key characteristic: the software remains in control.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI-Powered Workflows</span>"
    ]
  },
  {
    "objectID": "chapter3.html#what-workflows-are",
    "href": "chapter3.html#what-workflows-are",
    "title": "3  AI-Powered Workflows",
    "section": "",
    "text": "3.1.1 The Core Pattern\nThink of a workflow as a recipe that occasionally calls on AI for specific steps:\n1. Receive user input\n2. Validate the input (traditional code)\n3. Call AI to extract information\n4. Check the AI's confidence score (traditional code)\n5. If confidence &gt; threshold: Proceed\n6. Else: Route to human review\n7. Use extracted information in downstream processes\n8. Log everything to the database\nThe software defines every step. The software decides when to call the AI. The software interprets the results and decides what to do next.\nThe AI provides capabilities (classification, extraction, generation) but not decision-making authority.\n\n\n3.1.2 A Concrete Example\nConsider an automated customer support ticket routing system:\nInput: Customer email arrives Workflow: 1. Extract email body and subject (traditional code) 2. Call AI to classify urgency (High/Medium/Low) and category (Billing/Technical/Sales) 3. Receive: Urgency=High (92% confidence), Category=Billing (78% confidence) 4. Software checks rules: - If urgency ≥ 80% confident AND category ≥ 75% confident: Route automatically - Otherwise: Add to manual review queue 5. In this case: Route to “High Priority Billing” queue 6. Call AI again to generate a suggested initial response 7. Store ticket, classification, and suggested response in database 8. Notify on-call billing support rep\nWhat the AI did: - Classified the urgency level - Categorized the ticket type - Generated a suggested response\nWhat the software did: - Decided when to call the AI - Set confidence thresholds - Made routing decisions - Handled all state management and data storage - Controlled the entire flow\nThis is a workflow. The AI is a capable assistant, but the software is the boss.\n\n\n3.1.3 The Hallmarks of Workflows\nYou’re working with a workflow if:\n\nPredetermined logic: The software has explicit code for what happens at each step\nConditional branches: If/then logic based on AI outputs, but all branches are predefined\nAI as a function: AI models are called like any other function—send input, get output, continue\nHuman escalation paths: Clear handoff points when AI isn’t confident enough\nTraditional testing: You can write tests that verify specific inputs produce expected outputs through the workflow",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI-Powered Workflows</span>"
    ]
  },
  {
    "objectID": "chapter3.html#common-workflow-patterns",
    "href": "chapter3.html#common-workflow-patterns",
    "title": "3  AI-Powered Workflows",
    "section": "3.2 Common Workflow Patterns",
    "text": "3.2 Common Workflow Patterns\nLet’s explore the most common patterns for integrating AI into workflows. These patterns appear repeatedly across different industries and use cases.\n\n3.2.1 Classification and Routing\nThe simplest pattern: Use AI to categorize inputs, then route them accordingly.\nEmail spam filtering:\nEmail → Spam classifier →\n  If probability &gt; 0.95: Move to spam\n  If probability 0.50-0.95: Apply additional rules\n  If probability &lt; 0.50: Deliver to inbox\nSupport ticket categorization:\nTicket → Category classifier →\n  Technical issue → Technical support queue\n  Billing question → Billing team queue\n  Sales inquiry → Sales team queue\nContent moderation:\nUser comment → Toxicity classifier →\n  Score &gt; 0.9: Auto-remove and flag\n  Score 0.5-0.9: Queue for human review\n  Score &lt; 0.5: Auto-approve and publish\nThe pattern is consistent: classify, check thresholds, route based on predefined rules.\n\n\n3.2.2 Extraction and Transformation\nUse AI to extract structured information from unstructured data, then process it with traditional code.\nInvoice processing:\nInvoice PDF → OCR → Text\n           → LLM extraction →\n             {vendor, amount, date, line_items}\n           → Validate extracted data\n           → If valid: Insert into accounting system\n           → If invalid: Flag for manual review\nResume parsing:\nResume document → LLM extraction →\n                {name, email, skills[], experience[]}\n              → Match skills against job requirements\n              → Calculate fit score\n              → If score &gt; threshold: Add to interview pool\nMeeting notes processing:\nMeeting transcript → LLM extraction →\n                   {action_items[], decisions[], attendees[]}\n                 → Create tasks in project management system\n                 → Send summary email to attendees\nThe AI handles the hard part (understanding unstructured content), while traditional code handles the structured processing.\n\n\n3.2.3 Generation with Templates\nUse AI to generate content, but within well-defined templates and constraints.\nPersonalized email campaigns:\nFor each customer:\n  → Retrieve customer data (purchase history, preferences)\n  → Generate personalized email body using LLM\n  → Apply brand guidelines and template\n  → Add standard header/footer\n  → If email passes quality checks: Queue for sending\n  → If email fails checks: Flag for human review\nReport generation:\nGather data from database\n→ Call LLM to generate narrative analysis\n→ Insert generated text into report template\n→ Add charts and tables (traditional code)\n→ Apply formatting and branding\n→ Generate PDF\nProduct description writing:\nProduct specs from database\n→ LLM generates marketing copy\n→ Check generated copy against brand guidelines\n→ Run through readability analyzer\n→ If passes all checks: Publish to website\n→ If fails: Queue for editor review\nThe software controls what’s generated, when, and what happens with the results.\n\n\n3.2.4 Scoring and Ranking\nUse AI to score or rank items, then apply business logic to the scores.\nLead scoring:\nNew lead data → LLM analyzes fit based on criteria\n              → Outputs score 0-100\n→ If score &gt; 80: Assign to senior sales rep immediately\n→ If score 50-80: Add to nurture campaign\n→ If score &lt; 50: Add to low-priority list\nContent quality ranking:\nFor each article:\n  → LLM evaluates quality, relevance, engagement potential\n  → Outputs scores for each dimension\n  → Combine scores using weighted formula\n  → Rank all articles\n  → Promote top 10 to homepage\nCandidate ranking:\nFor each applicant:\n  → LLM evaluates resume against job description\n  → Outputs match score with explanation\n  → Sort all candidates by score\n  → Auto-advance top 20% to phone screen\n  → Auto-reject bottom 30% with kind message\n  → Middle 50% requires recruiter review\nThe AI provides the nuanced evaluation that would be hard to code explicitly, while the software makes the operational decisions.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI-Powered Workflows</span>"
    ]
  },
  {
    "objectID": "chapter3.html#the-power-and-limitations-of-workflows",
    "href": "chapter3.html#the-power-and-limitations-of-workflows",
    "title": "3  AI-Powered Workflows",
    "section": "3.3 The Power and Limitations of Workflows",
    "text": "3.3 The Power and Limitations of Workflows\nWorkflows are powerful—they represent how most companies successfully deploy AI today. But they also have inherent limitations. Understanding both is crucial for choosing the right approach.\n\n3.3.1 The Power: Predictability and Control\nWorkflows are auditable Every decision point is explicit in code. You can trace exactly why a ticket was routed to a specific queue or why an application was rejected. This auditability is crucial for compliance, debugging, and building trust.\nWorkflows are testable You can write comprehensive test suites: - Mock the AI responses - Verify the workflow behaves correctly for different AI outputs - Test edge cases and error conditions - Ensure confidence thresholds work as intended\nWorkflows are controllable If something goes wrong, you can: - Adjust thresholds - Add validation rules - Insert human review checkpoints - Modify routing logic\nAll without retraining models or changing prompts (though you might do that too).\nWorkflows are understandable Developers can read the code and understand the system’s behavior. Product managers can review the logic and make informed decisions about business rules. Operations teams can monitor specific decision points.\nWorkflows are safe Because every action is predefined, you can’t get surprising behavior outside the designed parameters. The system might make mistakes (AI classification errors), but it won’t suddenly start doing things you didn’t program it to do.\n\n\n3.3.2 The Limitations: Rigidity and Designer Dependency\nLimited by designer imagination The workflow can only handle scenarios you anticipated and coded for. Unexpected situations must either fit into existing categories or fall through to human escalation.\nExample: Your support ticket classifier knows categories: Billing, Technical, Sales, Account. A customer submits a ticket about a legal concern regarding their data. The system must either force it into one of these buckets (probably wrong) or escalate to humans.\nCannot adapt to novel situations If the world changes, the workflow stays the same until someone updates the code.\nExample: Your lead scoring workflow weighs factors like company size and budget. A new market trend makes company age a crucial factor. The workflow doesn’t adapt—someone must identify this, update the code, test it, and deploy.\nBrittle to variations Each variation requires explicit handling.\nExample: Invoice processing workflow expects standard invoice formats. A vendor sends an invoice with a different layout. The extraction might fail, or worse, extract the wrong data. You must handle each format variation explicitly.\nInefficient for complex decision trees As scenarios multiply, the code becomes an unmaintainable maze of conditionals.\nExample: Medical diagnosis support with hundreds of symptoms and thousands of possible conditions. Explicitly coding all the decision logic is impractical.\nCannot reason through multi-step problems The workflow defines the steps. It can’t think through “how should I approach this unusual situation?”\nExample: A customer’s issue involves both billing and technical problems, plus they mentioned a competitor. A workflow routes it to one queue or splits it into separate tickets. An intelligent agent might recognize this needs special handling—perhaps a senior representative who can address everything in one conversation and is empowered to offer retention incentives.\n\n\n3.3.3 When Workflows Excel\nDespite these limitations, workflows are the right choice for many applications:\n\nHigh-volume, well-defined tasks: Processing millions of transactions with known categories\nSafety-critical operations: Where you need guaranteed behavior within specific parameters\nRegulated environments: Where auditability and explainability are non-negotiable\nStable problem domains: Where the scenarios don’t change frequently\nCost-sensitive applications: Where the overhead of agent reasoning doesn’t justify the flexibility",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI-Powered Workflows</span>"
    ]
  },
  {
    "objectID": "chapter3.html#what-workflows-are-and-are-not",
    "href": "chapter3.html#what-workflows-are-and-are-not",
    "title": "3  AI-Powered Workflows",
    "section": "3.4 What Workflows Are and Are Not",
    "text": "3.4 What Workflows Are and Are Not\nLet’s be crystal clear about the distinction:\n\n3.4.1 What AI-Powered Workflows Are\nDeterministic processes that use AI for specific subtasks\nThe workflow is a predetermined recipe. AI provides capabilities (classification, extraction, generation) for specific steps. The software orchestrates everything and makes all control-flow decisions.\nThink of it like a factory assembly line. Each station has specific equipment and performs a defined operation. Some stations might have very sophisticated equipment (the AI components), but the sequence of operations, the decision criteria for quality control, and the routing logic are all predetermined.\nTraditional software with AI components\nThese are fundamentally software engineering projects that happen to integrate AI. You use standard software development practices: - Version control for the workflow logic - Unit and integration tests - Deployment pipelines - Monitoring and alerting - Incident response procedures\nThe AI components are just particularly sophisticated functions you’re calling.\nThe pragmatic starting point for most AI adoption\nFor teams new to AI integration, workflows offer: - Lower risk (controlled behavior) - Faster initial value (solve specific pain points) - Easier debugging (explicit logic) - Clearer ROI (measure impact at specific steps) - Foundation for future agent development (you learn what works)\n\n\n3.4.2 What AI-Powered Workflows Are Not\nSystems that can reason about novel problems\nA workflow cannot step back and think “this situation is unusual, I should approach it differently.” It executes its predetermined logic, period.\nAdaptive decision-makers\nThe workflow doesn’t learn from experience during operation (unless you explicitly build feedback loops and retraining pipelines). It doesn’t adjust its approach based on outcomes.\nSystems that choose their own path\nEvery possible path through a workflow is defined in code. The AI might influence which path is taken (through its classifications or scores), but the paths themselves are predetermined.\nIf you find yourself thinking “I wish the system could just figure out what to do in this case,” you’ve hit the boundary of what workflows can do. That’s where agents come in.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI-Powered Workflows</span>"
    ]
  },
  {
    "objectID": "chapter3.html#the-bridge-to-agents",
    "href": "chapter3.html#the-bridge-to-agents",
    "title": "3  AI-Powered Workflows",
    "section": "3.5 The Bridge to Agents",
    "text": "3.5 The Bridge to Agents\nUnderstanding workflows is essential preparation for understanding agents because agents are defined by what workflows cannot do.\nWorkflows: Software defines every step. AI provides capabilities. Software makes decisions.\nAgents: You define the goal. AI decides what steps to take, which tools to use, and adapts based on what it finds.\nIn the next chapter, we’ll explore this fundamental shift—what happens when you give the AI model decision-making authority and let it choose its own path toward a goal.\nBut before we get there, recognize that for many applications, workflows are not a compromise or a stepping stone. They’re the right solution. They provide AI capabilities within a controlled, predictable framework.\nThe question isn’t “should I use workflows or agents?” It’s “what does this specific application need?”\nSometimes you need the flexibility and reasoning of an agent. Sometimes you need the predictability and control of a workflow. And sometimes—as we’ll see in later chapters—you need both: agents that invoke workflows for specific subtasks.\nNow, let’s enter the world of agents.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI-Powered Workflows</span>"
    ]
  },
  {
    "objectID": "chapter4.html",
    "href": "chapter4.html",
    "title": "4  Enter the Agent",
    "section": "",
    "text": "4.1 The Defining Characteristic of Agents\nThe fundamental shift in how AI systems operate\nWe’ve arrived at the pivot point. Everything in the previous chapters—classification models, generative AI, workflows—has been building to this moment. We’re about to explore the concept that transforms AI from a tool your software uses into something fundamentally different: an agent.\nThe shift is conceptually simple but profound in its implications: What if the AI model makes the decisions about what to do next?\nThis chapter introduces the defining characteristic of agents, explores how they operate, and clarifies the critical distinction between using AI in workflows and deploying AI as agents.\nLet’s start with the clearest possible definition:\nAn AI agent is a system where the AI model decides which tools to call and what actions to take in pursuit of a goal.\nThat’s it. That’s the fundamental distinction.\nIn a workflow: The software decides when to call the AI and what to do with the results.\nIn an agent: The AI decides what to do next, including whether and when to use the tools available to it.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Enter the Agent</span>"
    ]
  },
  {
    "objectID": "chapter4.html#the-defining-characteristic-of-agents",
    "href": "chapter4.html#the-defining-characteristic-of-agents",
    "title": "4  Enter the Agent",
    "section": "",
    "text": "4.1.1 A Comparison\nWorkflow:\nSoftware: \"Classify this customer email\"\nAI: \"This is a billing issue, high priority\"\nSoftware: \"Thank you. I'll route it to the billing queue and\n          generate a suggested response\"\nAI: [not involved in these decisions]\nSoftware: \"Here's what I generated. Now I'll store it in the\n          database and notify the on-call rep\"\nAgent:\nYou: \"Handle this customer email appropriately\"\nAgent: [reads email] \"This is a billing issue. Let me check\n       the customer's account history first\"\nAgent: [calls account lookup tool]\nAgent: [reviews results] \"I see they've had billing problems\n       before. Let me check our knowledge base for the\n       standard resolution process\"\nAgent: [searches knowledge base]\nAgent: [reviews findings] \"I have enough information. I'll\n       draft a response, route this to the priority queue,\n       and attach the relevant account history\"\nAgent: [calls email drafting tool, queue routing tool,\n       attachment tool]\nAgent: \"Task complete. Email routed to priority billing queue\n       with drafted response and full context\"\nNotice the difference:\n\nWorkflow: Software pre-programmed every step\nAgent: AI reasoned through the situation and decided its own approach\n\nThe agent still used tools (account lookup, knowledge base search, email drafting). But the agent chose which tools to use, in what order, based on what it discovered along the way.\n\n\n4.1.2 What This Enables\nWhen the AI model controls the decision-making:\n\nAdaptability: The agent can handle situations the designer didn’t explicitly anticipate\nMulti-step reasoning: The agent can chain together multiple actions toward a goal\nContext-aware decisions: The agent can adjust its approach based on what it finds\nTool composition: The agent can combine tools in novel ways\nGoal-oriented behavior: You specify what you want achieved, not how to achieve it\n\n\n\n4.1.3 What This Requires\nThis shift also demands new approaches:\n\nTrust: You must trust the agent to make reasonable decisions\nMonitoring: You need to observe what the agent is doing, not just what it produces\nConstraints: You must define boundaries around what the agent can do\nError handling: The agent might take unexpected paths, including wrong ones\nTool design: Tools must be self-descriptive so the agent knows when to use them",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Enter the Agent</span>"
    ]
  },
  {
    "objectID": "chapter4.html#the-agentic-loop",
    "href": "chapter4.html#the-agentic-loop",
    "title": "4  Enter the Agent",
    "section": "4.2 The Agentic Loop",
    "text": "4.2 The Agentic Loop\nAgents operate through a fundamental pattern called the agentic loop (also called the ReAct loop, for Reasoning + Acting). Understanding this loop is essential for working with agents effectively.\n\n4.2.1 The Loop Structure\n1. Observe the current state\n2. Reason about what to do next\n3. Decide on an action\n4. Execute the action (call a tool)\n5. Observe the result\n6. Repeat until the task is complete (or limits are reached)\nThis is fundamentally different from executing a predetermined sequence of steps. The agent is continuously assessing the situation and deciding its next move.\n\n\n4.2.2 A Detailed Example\nLet’s walk through an agent completing a task: “Find the total amount spent by customer ID 12345 last month and send them a thank you email if it’s over $1000.”\nIteration 1: - Observe: I have a task about customer 12345, needing to check spending and conditionally send email - Reason: I need spending data first. I should query the database - Decide: Use the query_database tool - Execute: query_database(customer_id=12345, date_range=\"last_month\") - Result: $1,247.89\nIteration 2: - Observe: Customer 12345 spent $1,247.89 last month (over $1000 threshold) - Reason: This qualifies for a thank you email. I should personalize it with the actual amount - Decide: Use the send_email tool - Execute: send_email(to=customer_12345_email, subject=\"Thank you!\", body=\"Thank you for your $1,247.89 in business last month...\") - Result: Email sent successfully\nIteration 3: - Observe: I’ve determined the spend amount and sent the qualifying thank you email - Reason: The task is complete - Decide: Stop - Execute: Return final summary\n\n\n4.2.3 What Makes This “Agentic”\nThe agent made several autonomous decisions:\n\nSequencing: It decided to query the database before sending the email (obvious here, but the agent reasoned through it rather than following a script)\nConditional logic: It evaluated whether $1,247.89 &gt; $1,000 and decided to send the email\nTool selection: It chose which tools to use from those available\nContent generation: It composed an email with the specific amount\nCompletion detection: It recognized when the task was done\n\nIn a workflow, every one of these decisions would be explicitly coded. In an agent, the AI model made them based on reasoning.\n\n\n4.2.4 The Loop in Practice\nReal agent implementations handle additional complexities:\nContext management: Each observation and action is added to the context window, so the agent “remembers” what it’s done.\nError handling: If a tool call fails, the agent observes the error and can reason about what to try next.\nIteration limits: To prevent infinite loops, agents typically have a maximum number of iterations.\nCost limits: Since each iteration involves LLM calls, agents may have budget limits.\nVerification steps: The agent might use a tool to verify results before proceeding.\n\n\n4.2.5 What the Loop Is and Isn’t\nWhat the agentic loop is: - An iterative cycle of reasoning and acting - The mechanism that gives agents their adaptability - A framework for multi-step problem-solving - Fundamentally non-deterministic (same task might be approached differently)\nWhat the agentic loop is not: - A predetermined sequence of steps - Guaranteed to take the optimal path - Limited to a single iteration (most real tasks need multiple) - Foolproof (the agent can reason incorrectly)",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Enter the Agent</span>"
    ]
  },
  {
    "objectID": "chapter4.html#tools-the-agents-hands",
    "href": "chapter4.html#tools-the-agents-hands",
    "title": "4  Enter the Agent",
    "section": "4.3 Tools: The Agent’s Hands",
    "text": "4.3 Tools: The Agent’s Hands\nAn agent without tools is just a chatbot—it can reason and generate text, but it can’t affect the world or access external information. Tools are what transform an LLM into an agent capable of doing work.\n\n4.3.1 What Is a Tool?\nA tool is a function that the agent can call. From the agent’s perspective, a tool is defined by:\n\nName: A clear, descriptive identifier\nDescription: What the tool does and when to use it\nParameters: What inputs it requires (with descriptions)\nReturn value: What information it provides back\n\nExample tool definition:\n{\n  \"name\": \"query_customer_database\",\n  \"description\": \"Queries the customer database for information about a specific customer. Use this when you need customer details, order history, or account status.\",\n  \"parameters\": {\n    \"customer_id\": {\n      \"type\": \"string\",\n      \"description\": \"The unique customer identifier\"\n    },\n    \"include_orders\": {\n      \"type\": \"boolean\",\n      \"description\": \"Whether to include order history (optional, defaults to false)\"\n    }\n  },\n  \"returns\": \"Customer object with requested information\"\n}\nThe agent reads these descriptions and decides when to use the tool based on its task.\n\n\n4.3.2 Common Tool Types\nInformation retrieval: - Database queries - Web searches - File reading - API calls to external services - Knowledge base searches\nActions and modifications: - Sending emails or messages - Creating or updating database records - File writing - Making API calls that change state - Running shell commands\nComputation and analysis: - Code execution (running Python, SQL, etc.) - Data transformation - Mathematical calculations - Report generation\nSpecialized domain tools: - Medical diagnosis lookups - Legal research databases - Financial data APIs - Inventory management systems\n\n\n4.3.3 How Agents Choose Tools\nThis is where the magic happens. The agent:\n\nReads the available tool descriptions (these are in its context)\nConsiders the current task and what’s been done so far\nReasons about which tool would help make progress\nDecides on a specific tool and parameters\nCalls the tool\nInterprets the result and continues reasoning\n\nExample decision-making process:\nTask: “Analyze sales trends for Q4”\nAgent’s reasoning: - “I need sales data. Looking at available tools…” - “I see query_database, read_file, and web_search” - “The task is about our sales data, so web_search isn’t appropriate” - “query_database is described as accessing sales records—that’s what I need” - “I’ll query for Q4 sales data”\nThe agent doesn’t have hardcoded logic saying “sales analysis → database query.” It reads the tool descriptions and reasons about which tool matches the need.\n\n\n4.3.4 Tool Design Principles\nSince agents choose tools based on descriptions, good tool design is crucial:\nClear, distinctive names: send_email is better than tool_5\nPrecise descriptions: Explain exactly what the tool does and when to use it - Good: “Sends an email to a specified recipient with subject and body. Use this when you need to communicate with users or stakeholders via email.” - Bad: “Handles email stuff”\nWell-documented parameters: Every parameter needs a clear description - Good: customer_id (string): The unique identifier for the customer, found in the customer database - Bad: id (string): The ID\nAppropriate scope: Each tool should do one thing well - Good: Separate tools for send_email and schedule_email - Bad: One mega-tool that does email, SMS, notifications, and calendar events\nUseful return values: Return information the agent might need for reasoning - Good: {\"email_sent\": true, \"message_id\": \"abc123\", \"recipient_confirmed\": \"user@example.com\"} - Bad: {\"status\": \"ok\"}\n\n\n4.3.5 Tool Limitations and Safety\nTools are powerful, which means they require careful consideration:\nThe agent can only use tools you provide: An agent without a send_email tool cannot send emails, no matter how much reasoning it does.\nThe agent might use tools incorrectly: It might misunderstand a description, pass wrong parameters, or use a tool at the wrong time.\nThe agent might not use a tool when it should: If the description doesn’t clearly match the agent’s interpretation of the task, it might overlook a useful tool.\nTools have real effects: If you give an agent a delete_database_table tool, it might use it. Tool design is security design.\nWe’ll explore tool design in much more depth in Chapter 7, and security considerations in Chapter 13.\n\n\n4.3.6 What Tools Are and Aren’t\nWhat tools are: - Capabilities you grant to the agent - Functions the agent can call to interact with the world - Described in natural language for the agent to understand - The mechanism that makes agents useful for real work\nWhat tools are not: - Guaranteed to be used (the agent chooses) - Foolproof (the agent might use them wrongly) - A complete specification of the agent’s behavior (the agent still reasons) - Traditional API calls from the software (the AI decides when to call them)",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Enter the Agent</span>"
    ]
  },
  {
    "objectID": "chapter4.html#workflows-vs.-agents-when-to-use-which",
    "href": "chapter4.html#workflows-vs.-agents-when-to-use-which",
    "title": "4  Enter the Agent",
    "section": "4.4 Workflows vs. Agents: When to Use Which",
    "text": "4.4 Workflows vs. Agents: When to Use Which\nWe now have enough context to address the critical question: When should you use a workflow versus an agent?\n\n4.4.1 Use Workflows When:\nYou know exactly what needs to happen - Processing invoices that follow standard formats - Routing support tickets based on clear categories - Sending scheduled reports with predictable content\nConsistency is critical - Regulatory compliance requirements demand identical processing - Brand guidelines must be followed precisely - Every instance must be handled the same way\nVolume is high and cost matters - Processing millions of transactions where agent reasoning overhead would be expensive - Margins are thin and you need efficient execution\nThe problem domain is stable - The scenarios don’t change frequently - New edge cases are rare - The workflow can be updated occasionally when needed\nAuditability requires explicit logic - You need to point to specific code that explains decisions - Compliance demands transparent, predetermined rules\n\n\n4.4.2 Use Agents When:\nThe path to the goal isn’t predetermined - Researching a complex question that might require different sources depending on what you find - Debugging a problem where the next step depends on what each test reveals - Handling customer issues that might involve multiple interconnected problems\nAdaptability to variation is important - Inputs come in many different formats - Each instance might require a different approach - New scenarios emerge frequently\nMulti-step reasoning is required - The task requires chaining together multiple sub-tasks - Each step informs what should happen next - The sequence can’t be predicted in advance\nHuman-like judgment adds value - The task benefits from contextual understanding - There are nuances that are hard to code explicitly - The “right” answer depends on factors that are difficult to enumerate\nYou’re willing to trade control for capability - You can accept some unpredictability - You can implement appropriate safeguards - The benefits of flexibility outweigh the risks of non-determinism\n\n\n4.4.3 The Hybrid Approach: Agents That Invoke Workflows\nHere’s a sophisticated pattern: agents that have workflows as tools.\nExample: Customer support agent\nThe agent has these tools: - check_account_status (workflow: query database, apply business rules, return structured status) - process_refund (workflow: validate request, check policy, execute refund, send confirmation) - search_knowledge_base (workflow: embed query, semantic search, rank results, return top matches) - escalate_to_human (workflow: create ticket, route to appropriate team, notify)\nThe agent reasons about the customer’s issue and decides which tools to use, in what order.\nEach tool is a reliable workflow that does one thing well and predictably.\nThis combines the best of both: - Agent flexibility and reasoning for the overall task - Workflow reliability and auditability for critical operations\n\n\n4.4.4 The Spectrum\nThink of it as a spectrum rather than a binary choice:\nPure Workflow ← → Pure Agent\n\nTraditional software with     Agents that invoke      Agents with direct\nAI components at specific     workflows for critical  tool access to all\npredetermined points          operations              systems\nMost production systems will land somewhere in the middle, using agents for reasoning and decision-making while delegating well-defined operations to workflows.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Enter the Agent</span>"
    ]
  },
  {
    "objectID": "chapter4.html#what-weve-learned",
    "href": "chapter4.html#what-weve-learned",
    "title": "4  Enter the Agent",
    "section": "4.5 What We’ve Learned",
    "text": "4.5 What We’ve Learned\nThe shift from workflows to agents represents a fundamental change in how we build AI systems:\nWorkflows: - Software makes decisions - AI provides capabilities - Predetermined logic - Predictable behavior - Explicit control\nAgents: - AI makes decisions - Tools provide capabilities - Emergent behavior through reasoning - Adaptive approach - Guided autonomy\nThe agentic loop—observe, reason, act, repeat—is what gives agents their power. Tools are what let them do real work. And the design choice between workflows and agents depends on your specific needs around predictability, adaptability, and control.\nBut agents don’t exist in isolation. They need infrastructure to run, interfaces for humans to interact with them, and systems to manage their execution. That infrastructure is called an agent harness, and it’s what makes agents practical for real-world use.\nIn the next chapter, we’ll explore what agent harnesses do, how they’ve evolved, and why the current state of the art is dominated by CLI-based systems designed for coding tasks—which turn out to be much more general-purpose than they first appear.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Enter the Agent</span>"
    ]
  },
  {
    "objectID": "chapter5.html",
    "href": "chapter5.html",
    "title": "5  Agent Harnesses",
    "section": "",
    "text": "5.1 What an Agent Harness Does\nThe software that makes agents practical\nAn LLM with access to tools sounds powerful in theory. But how do you actually build and run such a system? How does the agentic loop get executed? How do tools get called? How do humans interact with the agent?\nThe answer is the agent harness—the infrastructure that turns an LLM into a practical, usable agent. Understanding what harnesses do and how they’ve evolved is essential for working with agents effectively.\nThis chapter explores the role of agent harnesses, traces their evolution from simple chat interfaces to sophisticated CLI tools, and examines why coding-focused harnesses dominate the current state of the art.\nAn agent harness is the software that sits between the user and the LLM, managing all the machinery that makes agency possible.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Agent Harnesses</span>"
    ]
  },
  {
    "objectID": "chapter5.html#what-an-agent-harness-does",
    "href": "chapter5.html#what-an-agent-harness-does",
    "title": "5  Agent Harnesses",
    "section": "",
    "text": "5.1.1 Core Responsibilities\n1. Managing the agentic loop\nThe harness implements the observe-reason-act-repeat cycle: - Sends the current state to the LLM - Receives the LLM’s decision about what to do next - If the LLM wants to call a tool: Execute the tool - Add the tool’s result to the context - Send the updated context back to the LLM - Repeat until the LLM signals completion (or limits are hit)\nThis orchestration is non-trivial. The harness must: - Format tool results appropriately - Handle tool execution errors - Manage timeouts and retries - Detect when the agent is stuck in a loop - Enforce iteration limits\n2. Providing tool infrastructure\nTools don’t just magically work. The harness must: - Register available tools and their descriptions - Validate tool calls (correct parameters, types, etc.) - Execute tools safely (sandboxing, permissions) - Capture tool outputs - Format results for the LLM to understand - Handle tool failures gracefully\n3. Managing the context window\nAs we learned in Chapter 2, context windows are large but not infinite. The harness must: - Track token usage - Decide what to keep when approaching limits - Summarize or remove old messages if needed - Optimize context to keep the most relevant information - Balance history (for coherence) with space (for tool results)\n4. Providing user interface\nUsers need to: - Send tasks to the agent - See what the agent is doing - Interrupt if necessary - Review results - Access conversation history\nThe harness provides this interface, whether it’s a chat window, a command-line interface, or an API.\n5. Managing security and sandboxing\nAgents can execute code, access files, and call APIs. The harness must: - Sandbox execution environments - Enforce permissions - Prevent unauthorized access - Rate limit expensive operations - Log all actions for audit\nWithout these safeguards, agents would be too dangerous to deploy.\n\n\n5.1.2 What Harnesses Enable\nThe harness transforms a stateless API call into a stateful, interactive agent:\nWithout a harness:\nYou → API call → LLM → Text response → You\nThat’s just text generation, not agency.\nWith a harness:\nYou → Task description → Agent harness\n                       → LLM decides to search web\n                       → Harness executes search\n                       → LLM reads results, decides to read a file\n                       → Harness reads file\n                       → LLM synthesizes information\n                       → Harness presents final answer\nThe harness made the agent possible.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Agent Harnesses</span>"
    ]
  },
  {
    "objectID": "chapter5.html#the-evolution-of-consumer-ai-interfaces",
    "href": "chapter5.html#the-evolution-of-consumer-ai-interfaces",
    "title": "5  Agent Harnesses",
    "section": "5.2 The Evolution of Consumer AI Interfaces",
    "text": "5.2 The Evolution of Consumer AI Interfaces\nTo understand modern agent harnesses, it helps to see how we got here. The evolution has been rapid and dramatic.\n\n5.2.1 Phase 1: Simple Text Generation (2020-2022)\nEarly public LLM interfaces like GPT-3’s Playground were essentially text completion tools:\n\nYou type a prompt\nThe model generates text\nThat’s it\n\nNo memory between sessions. No tools. No ability to access current information. If you asked “What’s the weather today?” the model would hallucinate an answer based on its training data patterns, not actual weather.\nThese weren’t agents. They were impressive text generators, but limited to the knowledge baked into their training data.\n\n\n5.2.2 Phase 2: Chat Interfaces with Memory (Late 2022)\nChatGPT launched in November 2022 and introduced something crucial: conversation memory within a session.\nThe interface maintained conversation history in context, so:\nYou: What's the capital of France?\nChatGPT: The capital of France is Paris.\nYou: What's the population?\nChatGPT: The population of Paris is approximately 2.2 million...\nThe model understood “What’s the population?” referred to Paris because the conversation history was in context.\nThis was a better user experience, but still not agency. The model still couldn’t access real-time information or take actions. It could only generate text based on training data and conversation history.\n\n\n5.2.3 Phase 3: Agents with Tools (2023-Present)\nThe transformation happened when chat interfaces became agent harnesses by adding tools.\nChatGPT with plugins (2023): - Web browsing plugin: Agent can search and read websites - Code interpreter: Agent can write and execute Python code - Third-party plugins: Access to specialized services\nClaude.ai with tools: - Web search: Access to current information - Document analysis: Upload and analyze files - Citations: Link to sources\nSuddenly, asking “What’s the weather today?” could work: 1. Agent recognizes it needs current information 2. Agent uses web search tool 3. Agent finds current weather 4. Agent provides accurate answer\nThese interfaces evolved from text generators to full agent harnesses.\n\n\n5.2.4 The Current State\nModern consumer AI interfaces are sophisticated agent harnesses:\nWhat they provide: - Conversation management (context window handling) - Multiple tools (search, code execution, document analysis) - File uploads and downloads - Session persistence - Safety guardrails - User controls (stop, regenerate, edit)\nWhat they don’t yet provide well: - Access to your local file system - Ability to run arbitrary commands on your computer - Integration with your development workflows - Deep customization of available tools\nThat last limitation is where CLI-based agent harnesses excel.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Agent Harnesses</span>"
    ]
  },
  {
    "objectID": "chapter5.html#the-current-state-of-the-art-cli-based-agent-harnesses",
    "href": "chapter5.html#the-current-state-of-the-art-cli-based-agent-harnesses",
    "title": "5  Agent Harnesses",
    "section": "5.3 The Current State of the Art: CLI-Based Agent Harnesses",
    "text": "5.3 The Current State of the Art: CLI-Based Agent Harnesses\nThe most powerful agent harnesses available today are command-line tools designed primarily for coding tasks. But as we’ll see, they’re actually general-purpose agents hiding in developer clothes.\n\n5.3.1 Major CLI Agent Harnesses\nClaude Code CLI - Developed by Anthropic for Claude models - File system access (read, write, edit) - Command execution (run terminal commands) - Git integration - Web search and fetch - Full development workflow support\nGitHub Copilot Workspace / Codex CLI - Integrated with GitHub - Code generation and editing - Repository understanding - Pull request and issue integration\nCursor / Cursor Agent Mode - IDE integration (VS Code fork) - Real-time code editing - Codebase awareness - Terminal access - Multi-file operations\nGemini CLI - Google’s offering - Similar capabilities to Claude Code - File system and command access - Integration with Google services\n\n\n5.3.2 Why CLI? The Architecture Makes Sense\nCLI-based harnesses excel because:\n1. File system access\nAgents can read any file, write new files, and edit existing ones. This enables: - Reading code to understand it - Editing files to fix bugs or add features - Creating new components - Processing data files\n2. Command execution\nAgents can run terminal commands: - Install dependencies (npm install, pip install) - Run tests (pytest, npm test) - Build projects (make, cargo build) - Execute scripts - Query databases - Deploy applications\n3. Integration with development workflows\nDevelopers already work in terminals. CLI agents fit naturally into existing practices: - Use your preferred editor with agent assistance - Run agents from your project directory - Integrate with shell scripts and automation - Access the same environment and credentials\n4. Powerful tool ecosystem\nThe command line provides access to: - Compilers and interpreters - Testing frameworks - Linters and formatters - Version control (git) - Database clients - Cloud CLIs (AWS, Azure, GCP) - Package managers\nAll of these become potential tools for the agent.\n5. Immediate feedback loops\nThe agent can: - Write code - Run it - See the results (output, errors, test results) - Adjust and iterate\nThis tight feedback loop enables rapid problem-solving.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Agent Harnesses</span>"
    ]
  },
  {
    "objectID": "chapter5.html#why-coding-dominates-current-agent-use",
    "href": "chapter5.html#why-coding-dominates-current-agent-use",
    "title": "5  Agent Harnesses",
    "section": "5.4 Why Coding Dominates Current Agent Use",
    "text": "5.4 Why Coding Dominates Current Agent Use\nThere’s a reason so much agent development has focused on code. It’s not because agents are only good at coding—it’s because coding is an ideal domain for agents.\n\n5.4.1 Code Is Text\nLLMs are fundamentally text prediction models. Code is text. This alignment means:\n\nAgents can read and write code naturally\nNo need for specialized output formats (unlike images or structured data)\nThe agent’s native medium matches the task medium\n\n\n\n5.4.2 Rich Feedback\nCode provides immediate, unambiguous feedback:\ndef add(a, b):\n    return a - b  # Bug: should be a + b\nRun it:\n&gt;&gt;&gt; add(2, 3)\n5  # Expected: 5, Got: 5... wait, this is wrong\n&gt;&gt;&gt; add(2, 3)\n-1  # Bug revealed\nThe agent can: - Write code - Execute it - See it fail - Understand the error - Fix it - Verify the fix\nThis feedback loop is clearer than in many other domains.\n\n\n5.4.3 Existing Tool Ecosystem\nSoftware development has decades of tooling: - Test frameworks that output pass/fail - Linters that identify issues - Compilers that report errors - Debuggers that trace execution - Profilers that measure performance\nAll of these tools were designed to provide information to developers. They work equally well for AI agents.\n\n\n5.4.4 Deterministic Verification\nYou can verify code works: - Run tests (pass or fail) - Check output (matches expected or doesn’t) - Execute and observe (works or errors)\nThis makes it easier to know when an agent has succeeded, unlike subjective tasks like “write a good essay.”\n\n\n5.4.5 Massive Training Data\nLLMs were trained on huge amounts of code: - Open source repositories (GitHub, etc.) - Stack Overflow discussions - Documentation - Books and tutorials\nThis means agents have strong priors for coding tasks.\n\n\n5.4.6 Composable Operations\nCode tasks break down into clear sub-tasks: - Read this file - Find the bug - Write a fix - Run tests - Commit changes\nEach sub-task is well-defined and verifiable, making them ideal for the agentic loop.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Agent Harnesses</span>"
    ]
  },
  {
    "objectID": "chapter5.html#the-key-insight-these-are-general-purpose-agents",
    "href": "chapter5.html#the-key-insight-these-are-general-purpose-agents",
    "title": "5  Agent Harnesses",
    "section": "5.5 The Key Insight: These Are General-Purpose Agents",
    "text": "5.5 The Key Insight: These Are General-Purpose Agents\nHere’s what most people miss: Claude Code, Cursor, and similar tools are not coding-specific agents. They’re general-purpose agents that happen to have great coding tools.\nThink about what these agents actually have access to:\n\nFile system: Read and write any files\nCommand execution: Run any terminal command\nWeb access: Fetch information from the internet\nCode execution: Run Python, JavaScript, shell scripts, etc.\n\nWith these capabilities, the agent can:\n\nProcess data files (CSV, JSON, XML)\nGenerate reports (Markdown, PDF, HTML)\nInteract with APIs (curl, API clients)\nAutomate system administration\nManage databases (SQL queries)\nSend emails (using command-line mail clients)\nProcess images (using ImageMagick or similar)\nAnything you can do in a terminal\n\n\n5.5.1 Beyond Code: Real Use Cases\nData analysis:\nYou: \"Analyze sales_data.csv and create a summary report with key trends\"\nAgent:\n  1. Reads CSV file\n  2. Writes Python script to analyze data\n  3. Executes script\n  4. Generates Markdown report with findings\n  5. Creates visualizations\nSystem administration:\nYou: \"Check disk usage across all servers in servers.txt and alert if any are &gt;80% full\"\nAgent:\n  1. Reads servers list\n  2. Writes script to SSH and check disk usage\n  3. Executes checks\n  4. Summarizes results\n  5. Highlights problems\nContent processing:\nYou: \"Convert all Word docs in /documents to PDF and organize by year\"\nAgent:\n  1. Lists .docx files\n  2. Runs conversion command for each\n  3. Extracts dates from metadata\n  4. Organizes into year-based directories\nNone of these are “coding” in the traditional sense. They’re automation tasks that happen to use code as a tool.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Agent Harnesses</span>"
    ]
  },
  {
    "objectID": "chapter5.html#what-harnesses-are-and-are-not",
    "href": "chapter5.html#what-harnesses-are-and-are-not",
    "title": "5  Agent Harnesses",
    "section": "5.6 What Harnesses Are and Are Not",
    "text": "5.6 What Harnesses Are and Are Not\nLet’s clarify the role of the harness:\n\n5.6.1 What Agent Harnesses Are\nInfrastructure that turns an LLM into a practical agent\nThe harness is the scaffolding: - Orchestrates the agentic loop - Provides and executes tools - Manages context and state - Handles security and sandboxing - Provides user interface\nWithout the harness, you just have an LLM API.\nMultipliers of the model’s capabilities\nThe harness doesn’t make the model smarter, but it makes the model’s intelligence applicable to real-world tasks by giving it hands (tools) and memory (context management).\nConfigurable platforms\nModern harnesses let you: - Add custom tools - Set system prompts - Configure behavior - Define permissions and limits\nYou can adapt them to your specific needs.\n\n\n5.6.2 What Agent Harnesses Are Not\nThe intelligence itself\nThe harness doesn’t make decisions or reason. That’s the LLM’s job. The harness is infrastructure, not intelligence.\nA better harness can make an agent more capable (by providing better tools) or safer (through better sandboxing), but it can’t make the underlying model smarter.\nCoding-specific (despite appearances)\nCLI-based harnesses are designed with developers in mind, but their capabilities are general-purpose. File access and command execution enable far more than just coding.\nOne-size-fits-all solutions\nDifferent harnesses make different trade-offs: - ChatGPT: Easy to use, limited control, no local access - Claude Code: Powerful local access, requires CLI comfort - Cursor: IDE integration, development focus - Custom harnesses: Maximum flexibility, requires building\nChoose based on your needs.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Agent Harnesses</span>"
    ]
  },
  {
    "objectID": "chapter5.html#looking-ahead",
    "href": "chapter5.html#looking-ahead",
    "title": "5  Agent Harnesses",
    "section": "5.7 Looking Ahead",
    "text": "5.7 Looking Ahead\nAgent harnesses are evolving rapidly. Current trends:\nMore customization: Easier ways to add custom tools and configure behavior\nBetter context management: Smarter strategies for handling long conversations and large codebases\nImproved safety: More sophisticated sandboxing and permission systems\nDomain-specific harnesses: Specialized harnesses for healthcare, legal, finance, etc.\nCross-platform agents: Agents that work across desktop, mobile, and web\nBut the fundamental insight remains: Agents need harnesses to be practical, and the best harnesses provide powerful tools while maintaining safety and usability.\nIn the next chapter, we’ll explore a crucial realization: The general-purpose agent is already here, hiding in plain sight. Claude Code and its peers aren’t just for code—they’re platforms for agent-powered automation of almost any task you can accomplish through files and commands.\nAnd with custom tools, they become even more powerful.",
    "crumbs": [
      "Part II: From Workflows to Agents — A Critical Distinction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Agent Harnesses</span>"
    ]
  }
]